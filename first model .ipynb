{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-212e7f7b4f92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdadelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# training model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontour\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcontour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridspec\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgridspec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\contour.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmcoll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont_manager\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfont_manager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmathtext\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmathtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLine2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFancyArrowPatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFancyBboxPatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRectangle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtextpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextPath\u001b[0m  \u001b[1;31m# Unused, but imported by others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m from .transforms import (\n\u001b[0;32m     19\u001b[0m     Affine2D, Bbox, BboxBase, BboxTransformTo, IdentityTransform, Transform)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping,TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adadelta\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# training model \n",
    "\n",
    "def imagegen(train_path,valid_path,test_path,batch_size):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Image generator function \n",
    "    \n",
    "    Parameters:\n",
    "    train_path - path to the training data set\n",
    "    valid_path - path to the validation data set\n",
    "    test_path - path to the test data set\n",
    "    batch_size - batch size \n",
    "    \n",
    "    \n",
    "    return: (train_generator, validation_generator, testing_generator)  \n",
    "    - training image generator, validation image generator, testing image generator \n",
    "    \n",
    "    '''\n",
    "\n",
    "    #training images augumentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,validation_split=0.2)\n",
    "\n",
    "    # validation augumentation \n",
    "    valid_datagen = ImageDataGenerator(rescale=1./255)# only rescaling\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)# only rescaling\n",
    "    # this is a generator that will read pictures found in\n",
    "    # subfolers of 'data/train', and indefinitely generate\n",
    "    # batches of augmented image data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_path,  # this is the target directory\n",
    "            target_size=image_size,  # all images will be resized to 150x150\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',subset='training')  # since categorical_crossentropy loss is used, we need binary labels\n",
    "\n",
    "    # this is a similar generator, for validation data\n",
    "    '''validation_generator = valid_datagen.flow_from_directory(\n",
    "            valid_path,\n",
    "            target_size=image_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')'''\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "            validation_path,  # this is the target directory\n",
    "            target_size=image_size,  # all images will be resized to 150x150\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',subset='validation')\n",
    "    \n",
    "    testing_generator = test_datagen.flow_from_directory(\n",
    "            test_path,\n",
    "            target_size=image_size,\n",
    "            batch_size=batch_size,\n",
    "            shuffle = False,\n",
    "            class_mode='categorical')\n",
    "    return train_generator, validation_generator, testing_generator\n",
    "\n",
    "def fit(model, model_name, image_generator, batch_size, epochs, no_train_img, no_valid_img):\n",
    "    \n",
    "    '''\n",
    "    training function to rain CNN model \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    model - CNN model\n",
    "    model_name - model name to save data \n",
    "    image_generator - generator to generate train/validation images\n",
    "    batch_size - batch size\n",
    "    epochs - number of epochs \n",
    "    no_train_img - number of training images\n",
    "    no_valid_img - number of validation images\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #tensorboary\n",
    "    print(model.summary())\n",
    "    tbc = TensorBoard(log_dir='/output/{}'.format(model_name), histogram_freq=0, write_graph=True, write_images=True)\n",
    "    \n",
    "    history =model.fit_generator(\n",
    "        image_generator[0],\n",
    "        steps_per_epoch=no_train_img // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=image_generator[1],\n",
    "        validation_steps=no_valid_img // batch_size,callbacks=[tbc]  )\n",
    "    \n",
    "    #save\n",
    "    model.save('{}.h5'.format(model_name)) \n",
    "    model.save_weights('{}_weights.h5'.format(model_name)) \n",
    "    \n",
    "    #plot\n",
    "    \n",
    "    # Loss Curves\n",
    "    plt.figure(figsize=[8,6]);\n",
    "    plt.plot(history.history['loss'],'r',linewidth=3.0);\n",
    "    plt.plot(history.history['val_loss'],'b',linewidth=3.0);\n",
    "    plt.legend(['Training loss', 'Validation Loss'],fontsize=18);\n",
    "    plt.xlabel('Epochs ',fontsize=16);\n",
    "    plt.ylabel('Loss',fontsize=16);\n",
    "    plt.title('Loss Curves {}'.format(model_name),fontsize=16);\n",
    "   \n",
    "\n",
    "    # Accuracy Curves\n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.plot(history.history['acc'],'r',linewidth=3.0);\n",
    "    plt.plot(history.history['val_acc'],'b',linewidth=3.0);\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18);\n",
    "    plt.xlabel('Epochs ',fontsize=16);\n",
    "    plt.ylabel('Accuracy',fontsize=16);\n",
    "    plt.title('Accuracy Curves {}'.format(model_name),fontsize=16);\n",
    "   \n",
    "\n",
    "    print(history.history['val_acc'][-1])\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "#plotting confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap='cividis'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "#test function\n",
    "    \n",
    "def predict(model,model_name,image_generator,no_images,batch_size):\n",
    "    \n",
    "    '''\n",
    "    Test function to test the CNN model \n",
    "    \n",
    "    \n",
    "    model - CNN model\n",
    "    model_name - model name to save data \n",
    "    image_generator - image generator to generate test images\n",
    "    batch_size = batch size \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    dict_characters = {1:'NORMAL',2:'L1',3:'L2',4:'L3'}\n",
    "    steps=no_images/batch_size\n",
    "    predictions = model.predict_generator(image_generator[2])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = image_generator[2].classes\n",
    "    class_labels = list(image_generator[2].class_indices.keys())\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "    print(report)  \n",
    "    cm =confusion_matrix(true_classes, predicted_classes)\n",
    "    cm_plot_labels = list(image_generator[2].class_indices.keys()) \n",
    "    plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix {}'.format(model_name))\n",
    "    batch_size = 32\n",
    "    image_size = (80, 60)\n",
    "    input_shape = (80, 60,3)\n",
    "    epochs = 15\n",
    "\n",
    "    #specify paths for train and test sets\n",
    "train_path = 'C:/Users/mon pc/Desktop/train'\n",
    "test_path = 'C:/Users/mon pc/Desktop/test'\n",
    "valid_path = 'C:/Users/mon pc/Desktop/validation'\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    raise Exception('No train folder found')\n",
    "\n",
    "if not os.path.exists(test_path):\n",
    "    raise Exception('No test folder found')\n",
    "\n",
    "image_generator=imagegen(train_path,valid_path,test_path,batch_size)\n",
    "\n",
    "model_name = 'Model_1'\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape,strides=1))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "fit(model1, model_name, image_generator, batch_size, epochs, 9957, 2487)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
